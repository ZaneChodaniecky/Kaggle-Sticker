{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ecc9be-8eb3-42cf-a103-f882ac54b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import socket\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import holidays\n",
    "import pycountry\n",
    "import optuna\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from termcolor import colored\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e47f6e-6e21-4e1f-976b-046d6019f9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d21237e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected. Ensure your setup is correct.\n",
      "CatBoost can use the GPU.\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from catboost.utils import get_gpu_device_count\n",
    "\n",
    "# Check available GPUs\n",
    "gpu_count = get_gpu_device_count()\n",
    "if gpu_count > 0:\n",
    "    print(f\"GPU is available with {gpu_count} GPU(s).\")\n",
    "else:\n",
    "    print(\"No GPU detected. Ensure your setup is correct.\")\n",
    "\n",
    "# Test CatBoost with GPU\n",
    "try:\n",
    "    model = CatBoostClassifier(task_type=\"GPU\", devices='0')  # Specify GPU\n",
    "    device = 'gpu'\n",
    "    print(\"CatBoost can use the GPU.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    device = 'cpu'\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee7c11a-7155-4d25-a8de-24e6c05d0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare important variables\n",
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'\n",
    "submission_path = 'sample_submission.csv'\n",
    "target_variable = 'num_sold'\n",
    "SEED = 69\n",
    "skip_hypertuning = True\n",
    "cat_encoder_type = 'OneHotEncoder' #OneHotEncoder, FrequencyEncoder, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a6afd61-d48c-4d0a-8272-39ad990662f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframes(path1: str, path2: str, format1: str = \"csv\", format2: str = \"csv\") -> tuple:\n",
    "\n",
    "    loaders = {\n",
    "        \"csv\": pd.read_csv,\n",
    "        \"excel\": pd.read_excel,\n",
    "        \"json\": pd.read_json,\n",
    "    }\n",
    "\n",
    "    if format1 not in loaders or format2 not in loaders:\n",
    "        raise ValueError(\"Unsupported format. Supported formats: 'csv', 'excel', 'json'.\")\n",
    "\n",
    "    # Load the dataframes using appropriate loaders\n",
    "    df1 = loaders[format1](path1)\n",
    "    df2 = loaders[format2](path2)\n",
    "\n",
    "    print(f\"Loading data from {os.getcwd()}\")\n",
    "    \n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fce9fbd-384a-4fac-8bbf-3eb68d30d172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from C:\\Users\\zchodan\\OneDrive - Franklin Templeton\\Documents\\Python\\Kaggle\\Playground Series\\s5e1 - Sticker Sales\n"
     ]
    }
   ],
   "source": [
    "train, test = load_dataframes(train_path,test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60d6e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the 'dataset' column to distinguish train and test data\n",
    "train['dataset'] = 'train'\n",
    "test['dataset'] = 'test'\n",
    "\n",
    "# concatenate the datasets with the added 'dataset' column\n",
    "df_original = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
    "df_original = df_original.rename(columns={target_variable: 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d828194-d954-4d0e-b48a-020dcd4d6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_kde_grid(df_train,n_cols=4,figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f42554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_kde_grid(df_solve,n_cols=4,figsize=(9,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81cb01aa-4360-417b-9fc7-4070a5384573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_cols(df: pd.DataFrame):\n",
    "    num_cols = df.select_dtypes(include=['number']).columns.to_list()\n",
    "    \n",
    "    return num_cols\n",
    "\n",
    "def get_cat_cols(df: pd.DataFrame):\n",
    "    cat_cols = df.select_dtypes(include=['object', 'string', 'category']).columns.tolist()  \n",
    "\n",
    "    return cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f68956-e3b5-45ab-a4d1-5be3e5a18fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a363157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_dataframe(df_to_use: pd.DataFrame, name: str = 'DataFrame', nrows: int = 3, plots: bool = False, info: bool = True) -> None:\n",
    "    '''\n",
    "    Function to describe the DataFrame with summary statistics, missing value count,\n",
    "    unique value count, and duplicate count. It also displays plots for missing and unique values.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: The DataFrame to describe.\n",
    "    - name: The name to display in the summary (default is 'DataFrame').\n",
    "    - nrows: The number of rows to display from the top and bottom (default is 3).\n",
    "    - plots: Whether to display bar plots for missing and unique values (default is False).\n",
    "    - info: Whether to display the styled DataFrame (default is True).\n",
    "    '''\n",
    "\n",
    "    df = df_to_use.copy()   \n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    inf = pd.DataFrame(df.dtypes).reset_index().rename(columns={'index':'column', 0:'type'})\n",
    "    \n",
    "    # Missing values\n",
    "    df_missing = pd.DataFrame(df.isnull().sum()).reset_index().rename(columns={'index':'column', 0:'missing'})\n",
    "    df_missing['pct_missing'] = (df_missing['missing'] / df.shape[0]) * 100\n",
    "    \n",
    "    # Unique values\n",
    "    df_unique = pd.DataFrame(df.nunique()).reset_index().rename(columns={'index':'column', 0:'unique'})\n",
    "    \n",
    "    # Combine summary information\n",
    "    inf['missing'] = df_missing['missing']\n",
    "    inf['pct_missing'] = df_missing['pct_missing']\n",
    "    inf['unique'] = df_unique['unique']\n",
    "    inf['duplicate'] = df.duplicated().sum()\n",
    "    inf['count'] = df.shape[0]\n",
    "\n",
    "    # Descriptive statistics\n",
    "    desc = pd.DataFrame(df.describe(include='all').transpose())\n",
    "    if 'min' in desc.columns.tolist():\n",
    "        inf['min'] = desc['min'].values\n",
    "        inf['max'] = desc['max'].values\n",
    "        inf['avg'] = desc['mean'].values\n",
    "        inf['std dev'] = desc['std'].values\n",
    "    if 'top' in desc.columns.tolist():\n",
    "        inf['top value'] = desc['top'].values\n",
    "        inf['Freq'] = desc['freq'].values \n",
    "    \n",
    "    # Display styled DataFrame\n",
    "    if info:\n",
    "        display(inf.style.background_gradient(subset=['missing','pct_missing'], cmap='Reds').background_gradient(subset='unique', cmap='Greens'))\n",
    "\n",
    "    if nrows != 0 :\n",
    "        # Display top and bottom nrows of the DataFrame\n",
    "        print(f\"\\n---------- {name} Overview ----------:\")\n",
    "        print(f\"{name} has {df.shape[0]} rows and {df.shape[1]} columns\\n\")\n",
    "        display(df.head(nrows))\n",
    "        display(df.tail(nrows))\n",
    "    \n",
    "    # Plot missing values if any\n",
    "    if plots and df_missing['missing'].sum() > 0:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(24, 5))\n",
    "        sns.barplot(df_missing[df_missing['missing'] > 0], x='column', y='missing', ax=ax)\n",
    "        ax.set_title(f'{name} missing Values') \n",
    "        ax.bar_label(ax.containers[0])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "        # Plot unique values\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(24, 5))\n",
    "        sns.barplot(df_unique[df_unique['unique'] > 0], x='column', y='unique', ax=ax)\n",
    "        ax.set_title(f'{name} Unique Values')\n",
    "        ax.bar_label(ax.containers[0])\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da182033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_826ec_row0_col2, #T_826ec_row0_col3, #T_826ec_row1_col2, #T_826ec_row1_col3, #T_826ec_row2_col2, #T_826ec_row2_col3, #T_826ec_row3_col2, #T_826ec_row3_col3, #T_826ec_row4_col2, #T_826ec_row4_col3, #T_826ec_row6_col2, #T_826ec_row6_col3 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_826ec_row0_col4 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_826ec_row1_col4 {\n",
       "  background-color: #f6fcf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_826ec_row2_col4, #T_826ec_row3_col4, #T_826ec_row4_col4, #T_826ec_row6_col4 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_826ec_row5_col2, #T_826ec_row5_col3 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_826ec_row5_col4 {\n",
       "  background-color: #f5fbf3;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_826ec\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_826ec_level0_col0\" class=\"col_heading level0 col0\" >column</th>\n",
       "      <th id=\"T_826ec_level0_col1\" class=\"col_heading level0 col1\" >type</th>\n",
       "      <th id=\"T_826ec_level0_col2\" class=\"col_heading level0 col2\" >missing</th>\n",
       "      <th id=\"T_826ec_level0_col3\" class=\"col_heading level0 col3\" >pct_missing</th>\n",
       "      <th id=\"T_826ec_level0_col4\" class=\"col_heading level0 col4\" >unique</th>\n",
       "      <th id=\"T_826ec_level0_col5\" class=\"col_heading level0 col5\" >duplicate</th>\n",
       "      <th id=\"T_826ec_level0_col6\" class=\"col_heading level0 col6\" >count</th>\n",
       "      <th id=\"T_826ec_level0_col7\" class=\"col_heading level0 col7\" >min</th>\n",
       "      <th id=\"T_826ec_level0_col8\" class=\"col_heading level0 col8\" >max</th>\n",
       "      <th id=\"T_826ec_level0_col9\" class=\"col_heading level0 col9\" >avg</th>\n",
       "      <th id=\"T_826ec_level0_col10\" class=\"col_heading level0 col10\" >std dev</th>\n",
       "      <th id=\"T_826ec_level0_col11\" class=\"col_heading level0 col11\" >top value</th>\n",
       "      <th id=\"T_826ec_level0_col12\" class=\"col_heading level0 col12\" >Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_826ec_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_826ec_row0_col0\" class=\"data row0 col0\" >id</td>\n",
       "      <td id=\"T_826ec_row0_col1\" class=\"data row0 col1\" >int64</td>\n",
       "      <td id=\"T_826ec_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_826ec_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "      <td id=\"T_826ec_row0_col4\" class=\"data row0 col4\" >328680</td>\n",
       "      <td id=\"T_826ec_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_826ec_row0_col6\" class=\"data row0 col6\" >328680</td>\n",
       "      <td id=\"T_826ec_row0_col7\" class=\"data row0 col7\" >0.000000</td>\n",
       "      <td id=\"T_826ec_row0_col8\" class=\"data row0 col8\" >328679.000000</td>\n",
       "      <td id=\"T_826ec_row0_col9\" class=\"data row0 col9\" >164339.500000</td>\n",
       "      <td id=\"T_826ec_row0_col10\" class=\"data row0 col10\" >94881.887576</td>\n",
       "      <td id=\"T_826ec_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_826ec_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_826ec_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_826ec_row1_col0\" class=\"data row1 col0\" >date</td>\n",
       "      <td id=\"T_826ec_row1_col1\" class=\"data row1 col1\" >object</td>\n",
       "      <td id=\"T_826ec_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_826ec_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "      <td id=\"T_826ec_row1_col4\" class=\"data row1 col4\" >3652</td>\n",
       "      <td id=\"T_826ec_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "      <td id=\"T_826ec_row1_col6\" class=\"data row1 col6\" >328680</td>\n",
       "      <td id=\"T_826ec_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_826ec_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_826ec_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_826ec_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_826ec_row1_col11\" class=\"data row1 col11\" >2010-01-01</td>\n",
       "      <td id=\"T_826ec_row1_col12\" class=\"data row1 col12\" >90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_826ec_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_826ec_row2_col0\" class=\"data row2 col0\" >country</td>\n",
       "      <td id=\"T_826ec_row2_col1\" class=\"data row2 col1\" >object</td>\n",
       "      <td id=\"T_826ec_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_826ec_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "      <td id=\"T_826ec_row2_col4\" class=\"data row2 col4\" >6</td>\n",
       "      <td id=\"T_826ec_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "      <td id=\"T_826ec_row2_col6\" class=\"data row2 col6\" >328680</td>\n",
       "      <td id=\"T_826ec_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_826ec_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_826ec_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_826ec_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_826ec_row2_col11\" class=\"data row2 col11\" >Canada</td>\n",
       "      <td id=\"T_826ec_row2_col12\" class=\"data row2 col12\" >54780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_826ec_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_826ec_row3_col0\" class=\"data row3 col0\" >store</td>\n",
       "      <td id=\"T_826ec_row3_col1\" class=\"data row3 col1\" >object</td>\n",
       "      <td id=\"T_826ec_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_826ec_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n",
       "      <td id=\"T_826ec_row3_col4\" class=\"data row3 col4\" >3</td>\n",
       "      <td id=\"T_826ec_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "      <td id=\"T_826ec_row3_col6\" class=\"data row3 col6\" >328680</td>\n",
       "      <td id=\"T_826ec_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "      <td id=\"T_826ec_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
       "      <td id=\"T_826ec_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
       "      <td id=\"T_826ec_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
       "      <td id=\"T_826ec_row3_col11\" class=\"data row3 col11\" >Discount Stickers</td>\n",
       "      <td id=\"T_826ec_row3_col12\" class=\"data row3 col12\" >109560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_826ec_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_826ec_row4_col0\" class=\"data row4 col0\" >product</td>\n",
       "      <td id=\"T_826ec_row4_col1\" class=\"data row4 col1\" >object</td>\n",
       "      <td id=\"T_826ec_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_826ec_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n",
       "      <td id=\"T_826ec_row4_col4\" class=\"data row4 col4\" >5</td>\n",
       "      <td id=\"T_826ec_row4_col5\" class=\"data row4 col5\" >0</td>\n",
       "      <td id=\"T_826ec_row4_col6\" class=\"data row4 col6\" >328680</td>\n",
       "      <td id=\"T_826ec_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
       "      <td id=\"T_826ec_row4_col8\" class=\"data row4 col8\" >nan</td>\n",
       "      <td id=\"T_826ec_row4_col9\" class=\"data row4 col9\" >nan</td>\n",
       "      <td id=\"T_826ec_row4_col10\" class=\"data row4 col10\" >nan</td>\n",
       "      <td id=\"T_826ec_row4_col11\" class=\"data row4 col11\" >Holographic Goose</td>\n",
       "      <td id=\"T_826ec_row4_col12\" class=\"data row4 col12\" >65736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_826ec_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_826ec_row5_col0\" class=\"data row5 col0\" >y</td>\n",
       "      <td id=\"T_826ec_row5_col1\" class=\"data row5 col1\" >float64</td>\n",
       "      <td id=\"T_826ec_row5_col2\" class=\"data row5 col2\" >107421</td>\n",
       "      <td id=\"T_826ec_row5_col3\" class=\"data row5 col3\" >32.682548</td>\n",
       "      <td id=\"T_826ec_row5_col4\" class=\"data row5 col4\" >4037</td>\n",
       "      <td id=\"T_826ec_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_826ec_row5_col6\" class=\"data row5 col6\" >328680</td>\n",
       "      <td id=\"T_826ec_row5_col7\" class=\"data row5 col7\" >5.000000</td>\n",
       "      <td id=\"T_826ec_row5_col8\" class=\"data row5 col8\" >5939.000000</td>\n",
       "      <td id=\"T_826ec_row5_col9\" class=\"data row5 col9\" >752.527382</td>\n",
       "      <td id=\"T_826ec_row5_col10\" class=\"data row5 col10\" >690.165445</td>\n",
       "      <td id=\"T_826ec_row5_col11\" class=\"data row5 col11\" >nan</td>\n",
       "      <td id=\"T_826ec_row5_col12\" class=\"data row5 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_826ec_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_826ec_row6_col0\" class=\"data row6 col0\" >dataset</td>\n",
       "      <td id=\"T_826ec_row6_col1\" class=\"data row6 col1\" >object</td>\n",
       "      <td id=\"T_826ec_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_826ec_row6_col3\" class=\"data row6 col3\" >0.000000</td>\n",
       "      <td id=\"T_826ec_row6_col4\" class=\"data row6 col4\" >2</td>\n",
       "      <td id=\"T_826ec_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_826ec_row6_col6\" class=\"data row6 col6\" >328680</td>\n",
       "      <td id=\"T_826ec_row6_col7\" class=\"data row6 col7\" >nan</td>\n",
       "      <td id=\"T_826ec_row6_col8\" class=\"data row6 col8\" >nan</td>\n",
       "      <td id=\"T_826ec_row6_col9\" class=\"data row6 col9\" >nan</td>\n",
       "      <td id=\"T_826ec_row6_col10\" class=\"data row6 col10\" >nan</td>\n",
       "      <td id=\"T_826ec_row6_col11\" class=\"data row6 col11\" >train</td>\n",
       "      <td id=\"T_826ec_row6_col12\" class=\"data row6 col12\" >230130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21352ac7ec0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "describe_dataframe(df_original, name='Insurance Data', nrows=0, plots=False, info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ae05780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "df_original.boxplot(column='y', by='country', grid=False)\n",
    "plt.title(\"Outliers in 'num_sold' by Country\")\n",
    "plt.suptitle(\"\")  # Removes the default matplotlib title\n",
    "plt.ylabel('Number of Units Sold')\n",
    "plt.xlabel('Country')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e3a9767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Outliers: 6630\n"
     ]
    }
   ],
   "source": [
    "# Calculate Outlier Bounds Using IQR\n",
    "# Calculating Interquartile Range (IQR) to identify potential outliers\n",
    "# Filtering rows where 'num_sold' is outside the lower and upper bounds\n",
    "\n",
    "# Recalculate Q1, Q3, and IQR\n",
    "Q1 = df_original['y'].quantile(0.25)\n",
    "Q3 = df_original['y'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define lower and upper bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter outliers\n",
    "outliers = df_original[(df_original['y'] < lower_bound) | (df_original['y'] > upper_bound)]\n",
    "print(f\"Number of Outliers: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b01de7b4-4ad1-4930-b2cc-3445e0f4640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers by Country:\n",
      "country\n",
      "Canada         11\n",
      "Finland        11\n",
      "Norway       6521\n",
      "Singapore      87\n",
      "dtype: int64\n",
      "Outliers by Store:\n",
      "store\n",
      "Discount Stickers          1\n",
      "Premium Sticker Mart    4175\n",
      "Stickers for Less       2454\n",
      "dtype: int64\n",
      "Outliers by Product:\n",
      "product\n",
      "Kaggle                4169\n",
      "Kaggle Tiers          2347\n",
      "Kerneler                 2\n",
      "Kerneler Dark Mode     112\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group outliers by country\n",
    "outliers_by_country = outliers.groupby('country').size()\n",
    "print(\"Outliers by Country:\")\n",
    "print(outliers_by_country)\n",
    "\n",
    "# Group outliers by store\n",
    "outliers_by_store = outliers.groupby('store').size()\n",
    "print(\"Outliers by Store:\")\n",
    "print(outliers_by_store)\n",
    "\n",
    "# Group outliers by product\n",
    "outliers_by_product = outliers.groupby('product').size()\n",
    "print(\"Outliers by Product:\")\n",
    "print(outliers_by_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a514938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df_to_use: pd.DataFrame, impute_num_nulls: bool = True, fill_cat_nulls: bool = True) -> None:\n",
    "    df = df_to_use.copy()\n",
    "\n",
    "    # Convert date column from object to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Filter columns where the type is either 'float' or 'int' and there are missing values\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    missing_numeric_columns = [\n",
    "        col for col in numeric_cols if df[col].isnull().sum() > 0\n",
    "    ]\n",
    "\n",
    "    # Target field 'num_sold' is missing some values, we do not want to impute them\n",
    "    if 'y' in missing_numeric_columns:\n",
    "        missing_numeric_columns.remove('y')\n",
    "    \n",
    "    # Fill nulls in numeric columns with the median\n",
    "    if impute_num_nulls:       \n",
    "        for column in missing_numeric_columns:\n",
    "            mdn = df[column].median()\n",
    "            df[column] = df[column].fillna(mdn)\n",
    "\n",
    "    \n",
    "    # Get category columns\n",
    "    if fill_cat_nulls:\n",
    "        cat_cols = df.select_dtypes(include=['object', 'string','category']).columns.tolist()  \n",
    "        # Fill missing values in object columns\n",
    "        for column in cat_cols:\n",
    "            df[column] = df[column].fillna('None')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b213027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = clean_dataframe(df_original, impute_num_nulls = True, fill_cat_nulls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a79de08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f613b_row0_col2, #T_f613b_row0_col3, #T_f613b_row1_col2, #T_f613b_row1_col3, #T_f613b_row2_col2, #T_f613b_row2_col3, #T_f613b_row3_col2, #T_f613b_row3_col3, #T_f613b_row4_col2, #T_f613b_row4_col3, #T_f613b_row6_col2, #T_f613b_row6_col3 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f613b_row0_col4 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f613b_row1_col4 {\n",
       "  background-color: #f6fcf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f613b_row2_col4, #T_f613b_row3_col4, #T_f613b_row4_col4, #T_f613b_row6_col4 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f613b_row5_col2, #T_f613b_row5_col3 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f613b_row5_col4 {\n",
       "  background-color: #f5fbf3;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f613b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f613b_level0_col0\" class=\"col_heading level0 col0\" >column</th>\n",
       "      <th id=\"T_f613b_level0_col1\" class=\"col_heading level0 col1\" >type</th>\n",
       "      <th id=\"T_f613b_level0_col2\" class=\"col_heading level0 col2\" >missing</th>\n",
       "      <th id=\"T_f613b_level0_col3\" class=\"col_heading level0 col3\" >pct_missing</th>\n",
       "      <th id=\"T_f613b_level0_col4\" class=\"col_heading level0 col4\" >unique</th>\n",
       "      <th id=\"T_f613b_level0_col5\" class=\"col_heading level0 col5\" >duplicate</th>\n",
       "      <th id=\"T_f613b_level0_col6\" class=\"col_heading level0 col6\" >count</th>\n",
       "      <th id=\"T_f613b_level0_col7\" class=\"col_heading level0 col7\" >min</th>\n",
       "      <th id=\"T_f613b_level0_col8\" class=\"col_heading level0 col8\" >max</th>\n",
       "      <th id=\"T_f613b_level0_col9\" class=\"col_heading level0 col9\" >avg</th>\n",
       "      <th id=\"T_f613b_level0_col10\" class=\"col_heading level0 col10\" >std dev</th>\n",
       "      <th id=\"T_f613b_level0_col11\" class=\"col_heading level0 col11\" >top value</th>\n",
       "      <th id=\"T_f613b_level0_col12\" class=\"col_heading level0 col12\" >Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f613b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f613b_row0_col0\" class=\"data row0 col0\" >id</td>\n",
       "      <td id=\"T_f613b_row0_col1\" class=\"data row0 col1\" >int64</td>\n",
       "      <td id=\"T_f613b_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_f613b_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "      <td id=\"T_f613b_row0_col4\" class=\"data row0 col4\" >328680</td>\n",
       "      <td id=\"T_f613b_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_f613b_row0_col6\" class=\"data row0 col6\" >328680</td>\n",
       "      <td id=\"T_f613b_row0_col7\" class=\"data row0 col7\" >0.000000</td>\n",
       "      <td id=\"T_f613b_row0_col8\" class=\"data row0 col8\" >328679.000000</td>\n",
       "      <td id=\"T_f613b_row0_col9\" class=\"data row0 col9\" >164339.500000</td>\n",
       "      <td id=\"T_f613b_row0_col10\" class=\"data row0 col10\" >94881.887576</td>\n",
       "      <td id=\"T_f613b_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_f613b_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f613b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f613b_row1_col0\" class=\"data row1 col0\" >date</td>\n",
       "      <td id=\"T_f613b_row1_col1\" class=\"data row1 col1\" >datetime64[ns]</td>\n",
       "      <td id=\"T_f613b_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_f613b_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "      <td id=\"T_f613b_row1_col4\" class=\"data row1 col4\" >3652</td>\n",
       "      <td id=\"T_f613b_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "      <td id=\"T_f613b_row1_col6\" class=\"data row1 col6\" >328680</td>\n",
       "      <td id=\"T_f613b_row1_col7\" class=\"data row1 col7\" >2010-01-01 00:00:00</td>\n",
       "      <td id=\"T_f613b_row1_col8\" class=\"data row1 col8\" >2019-12-31 00:00:00</td>\n",
       "      <td id=\"T_f613b_row1_col9\" class=\"data row1 col9\" >2014-12-31 12:00:00</td>\n",
       "      <td id=\"T_f613b_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_f613b_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_f613b_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f613b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f613b_row2_col0\" class=\"data row2 col0\" >country</td>\n",
       "      <td id=\"T_f613b_row2_col1\" class=\"data row2 col1\" >object</td>\n",
       "      <td id=\"T_f613b_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_f613b_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "      <td id=\"T_f613b_row2_col4\" class=\"data row2 col4\" >6</td>\n",
       "      <td id=\"T_f613b_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "      <td id=\"T_f613b_row2_col6\" class=\"data row2 col6\" >328680</td>\n",
       "      <td id=\"T_f613b_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_f613b_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_f613b_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_f613b_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_f613b_row2_col11\" class=\"data row2 col11\" >Canada</td>\n",
       "      <td id=\"T_f613b_row2_col12\" class=\"data row2 col12\" >54780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f613b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f613b_row3_col0\" class=\"data row3 col0\" >store</td>\n",
       "      <td id=\"T_f613b_row3_col1\" class=\"data row3 col1\" >object</td>\n",
       "      <td id=\"T_f613b_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_f613b_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n",
       "      <td id=\"T_f613b_row3_col4\" class=\"data row3 col4\" >3</td>\n",
       "      <td id=\"T_f613b_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "      <td id=\"T_f613b_row3_col6\" class=\"data row3 col6\" >328680</td>\n",
       "      <td id=\"T_f613b_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "      <td id=\"T_f613b_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
       "      <td id=\"T_f613b_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
       "      <td id=\"T_f613b_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
       "      <td id=\"T_f613b_row3_col11\" class=\"data row3 col11\" >Discount Stickers</td>\n",
       "      <td id=\"T_f613b_row3_col12\" class=\"data row3 col12\" >109560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f613b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f613b_row4_col0\" class=\"data row4 col0\" >product</td>\n",
       "      <td id=\"T_f613b_row4_col1\" class=\"data row4 col1\" >object</td>\n",
       "      <td id=\"T_f613b_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_f613b_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n",
       "      <td id=\"T_f613b_row4_col4\" class=\"data row4 col4\" >5</td>\n",
       "      <td id=\"T_f613b_row4_col5\" class=\"data row4 col5\" >0</td>\n",
       "      <td id=\"T_f613b_row4_col6\" class=\"data row4 col6\" >328680</td>\n",
       "      <td id=\"T_f613b_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
       "      <td id=\"T_f613b_row4_col8\" class=\"data row4 col8\" >nan</td>\n",
       "      <td id=\"T_f613b_row4_col9\" class=\"data row4 col9\" >nan</td>\n",
       "      <td id=\"T_f613b_row4_col10\" class=\"data row4 col10\" >nan</td>\n",
       "      <td id=\"T_f613b_row4_col11\" class=\"data row4 col11\" >Holographic Goose</td>\n",
       "      <td id=\"T_f613b_row4_col12\" class=\"data row4 col12\" >65736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f613b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f613b_row5_col0\" class=\"data row5 col0\" >y</td>\n",
       "      <td id=\"T_f613b_row5_col1\" class=\"data row5 col1\" >float64</td>\n",
       "      <td id=\"T_f613b_row5_col2\" class=\"data row5 col2\" >107421</td>\n",
       "      <td id=\"T_f613b_row5_col3\" class=\"data row5 col3\" >32.682548</td>\n",
       "      <td id=\"T_f613b_row5_col4\" class=\"data row5 col4\" >4037</td>\n",
       "      <td id=\"T_f613b_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_f613b_row5_col6\" class=\"data row5 col6\" >328680</td>\n",
       "      <td id=\"T_f613b_row5_col7\" class=\"data row5 col7\" >5.000000</td>\n",
       "      <td id=\"T_f613b_row5_col8\" class=\"data row5 col8\" >5939.000000</td>\n",
       "      <td id=\"T_f613b_row5_col9\" class=\"data row5 col9\" >752.527382</td>\n",
       "      <td id=\"T_f613b_row5_col10\" class=\"data row5 col10\" >690.165445</td>\n",
       "      <td id=\"T_f613b_row5_col11\" class=\"data row5 col11\" >nan</td>\n",
       "      <td id=\"T_f613b_row5_col12\" class=\"data row5 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f613b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f613b_row6_col0\" class=\"data row6 col0\" >dataset</td>\n",
       "      <td id=\"T_f613b_row6_col1\" class=\"data row6 col1\" >object</td>\n",
       "      <td id=\"T_f613b_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_f613b_row6_col3\" class=\"data row6 col3\" >0.000000</td>\n",
       "      <td id=\"T_f613b_row6_col4\" class=\"data row6 col4\" >2</td>\n",
       "      <td id=\"T_f613b_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_f613b_row6_col6\" class=\"data row6 col6\" >328680</td>\n",
       "      <td id=\"T_f613b_row6_col7\" class=\"data row6 col7\" >nan</td>\n",
       "      <td id=\"T_f613b_row6_col8\" class=\"data row6 col8\" >nan</td>\n",
       "      <td id=\"T_f613b_row6_col9\" class=\"data row6 col9\" >nan</td>\n",
       "      <td id=\"T_f613b_row6_col10\" class=\"data row6 col10\" >nan</td>\n",
       "      <td id=\"T_f613b_row6_col11\" class=\"data row6 col11\" >train</td>\n",
       "      <td id=\"T_f613b_row6_col12\" class=\"data row6 col12\" >230130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2135db74890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "describe_dataframe(df_original, name='Insurance Data', nrows=0, plots=False, info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f87d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c23432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holiday_name(country_code, date_obj):\n",
    "    try:\n",
    "        country_holiday = holidays.CountryHoliday(country_code, years=date_obj.year)\n",
    "        return country_holiday.get(date_obj)\n",
    "    except Exception as e:\n",
    "        print(f\"Error for country code {country_code} and date {date_obj}: {e}\")\n",
    "        return 'Invalid Holiday'\n",
    "    return country_holiday.get(date_obj)\n",
    "\n",
    "def get_country_code(country_name):\n",
    "    try:\n",
    "        country = pycountry.countries.get(name=country_name)\n",
    "        return country.alpha_2  \n",
    "    except KeyError:\n",
    "        print(f\"Unknown Country: {country_name}\")\n",
    "        return None\n",
    "\n",
    "def get_holiday_for_row(row):\n",
    "    country_code = get_country_code(row['country'])\n",
    "    if country_code is None:\n",
    "        return 'Unknown Country'     \n",
    "    try:\n",
    "        date_obj = row['date']\n",
    "    except ValueError:\n",
    "        print(f\"Invalid Date: {row['date']}\")\n",
    "        return 'Invalid Date'\n",
    "\n",
    "    return get_holiday_name(country_code, date_obj)\n",
    "\n",
    "\n",
    "df_original['holiday'] = df_original.apply(get_holiday_for_row, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1575c801-1a6c-4c6c-be9b-8bd984533d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting holiday takes a while, so lets split here so we can skip whil testing\n",
    "df = df_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35f7d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Year'] = df['date'].dt.year\n",
    "df['Quarter'] = df['date'].dt.quarter\n",
    "df['Month'] = df['date'].dt.month\n",
    "df['day_of_month'] = df['date'].dt.day\n",
    "df['day_of_week'] = df['date'].dt.day_name()\n",
    "#df['day_of_year'] = df['date'].dt.dayofyear\n",
    "df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "\n",
    "df['day_of_month_sin'] = np.sin(2 * np.pi * df['day_of_month'] / 31.0)\n",
    "df['day_of_month_cos'] = np.cos(2 * np.pi * df['day_of_month'] / 31.0)\n",
    "#df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365.0)\n",
    "#df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365.0)\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['Month'] / 12.0)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['Month'] / 12.0)\n",
    "df['year_sin'] = np.sin(2 * np.pi * df['Year'] / 7.0)\n",
    "df['year_cos'] = np.cos(2 * np.pi * df['Year'] / 7.0)\n",
    "df['Group']=(df['Year']-2010)*48+df['Month']*4+df['day_of_month']//7\n",
    "\n",
    "\n",
    "df['Quarter'] = df['Quarter'].astype('str')\n",
    "df['Month'] = df['Month'].astype('str')\n",
    "df['day_of_week'] = df['day_of_week'].astype('str')\n",
    "#df['day_of_year'] = df['day_of_year'].astype('str')\n",
    "df['week_of_year'] = df['week_of_year'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f80b5ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE 17 BASIC FEATURES ARE:\n",
      "country (categorical) with 6 unique values\n",
      "store (categorical) with 3 unique values\n",
      "product (categorical) with 5 unique values\n",
      "holiday (categorical) with 75 unique values\n",
      "Year (numerical) with 10 unique values\n",
      "Quarter (categorical) with 4 unique values\n",
      "Month (categorical) with 12 unique values\n",
      "day_of_month (numerical) with 31 unique values\n",
      "day_of_week (categorical) with 7 unique values\n",
      "week_of_year (categorical) with 53 unique values\n",
      "day_of_month_sin (numerical) with 31 unique values\n",
      "day_of_month_cos (numerical) with 16 unique values\n",
      "month_sin (numerical) with 8 unique values\n",
      "month_cos (numerical) with 8 unique values\n",
      "year_sin (numerical) with 7 unique values\n",
      "year_cos (numerical) with 4 unique values\n",
      "Group (numerical) with 481 unique values\n",
      "\n",
      "THE FOLLOWING HAVE 9 OR MORE UNIQUE VALUES: ['holiday', 'Year', 'Month', 'day_of_month', 'week_of_year', 'day_of_month_sin', 'day_of_month_cos', 'Group']\n"
     ]
    }
   ],
   "source": [
    "RMV = ['y','dataset','id','date']\n",
    "FEATURES = [c for c in df.columns if not c in RMV]\n",
    "\n",
    "CATS = []\n",
    "HIGH_CARDINALITY = []\n",
    "print(f\"THE {len(FEATURES)} BASIC FEATURES ARE:\")\n",
    "\n",
    "for c in FEATURES:\n",
    "    ftype = \"numerical\"\n",
    "    if df[c].dtype==\"object\":\n",
    "        CATS.append(c)\n",
    "        df[c] = df[c].fillna(\"NAN\")\n",
    "        df[c],_ = df[c].factorize() # Turns cats into integers\n",
    "        df[c] -= df[c].min() # Normalize to start from 0 so range is [0 : n-1]\n",
    "        ftype = \"categorical\"\n",
    "    if df[c].dtype==\"int64\":\n",
    "        df[c] = df[c].astype(\"int32\")\n",
    "    elif df[c].dtype==\"float64\":\n",
    "        df[c] = df[c].astype(\"float32\")\n",
    "\n",
    "    n = df[c].nunique()\n",
    "    print(f\"{c} ({ftype}) with {n} unique values\")\n",
    "    if n>=9: HIGH_CARDINALITY.append(c)\n",
    "\n",
    "print(\"\\nTHE FOLLOWING HAVE 9 OR MORE UNIQUE VALUES:\", HIGH_CARDINALITY )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72efa1e9-ac7a-4b4d-bc9c-1b7900e841da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57239c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c756b_row0_col2, #T_c756b_row0_col3, #T_c756b_row1_col2, #T_c756b_row1_col3, #T_c756b_row2_col2, #T_c756b_row2_col3, #T_c756b_row3_col2, #T_c756b_row3_col3, #T_c756b_row4_col2, #T_c756b_row4_col3, #T_c756b_row6_col2, #T_c756b_row6_col3, #T_c756b_row7_col2, #T_c756b_row7_col3, #T_c756b_row8_col2, #T_c756b_row8_col3, #T_c756b_row9_col2, #T_c756b_row9_col3, #T_c756b_row10_col2, #T_c756b_row10_col3, #T_c756b_row11_col2, #T_c756b_row11_col3, #T_c756b_row12_col2, #T_c756b_row12_col3, #T_c756b_row13_col2, #T_c756b_row13_col3, #T_c756b_row14_col2, #T_c756b_row14_col3, #T_c756b_row15_col2, #T_c756b_row15_col3, #T_c756b_row16_col2, #T_c756b_row16_col3, #T_c756b_row17_col2, #T_c756b_row17_col3, #T_c756b_row18_col2, #T_c756b_row18_col3, #T_c756b_row19_col2, #T_c756b_row19_col3, #T_c756b_row20_col2, #T_c756b_row20_col3 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c756b_row0_col4 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c756b_row1_col4 {\n",
       "  background-color: #f6fcf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c756b_row2_col4, #T_c756b_row3_col4, #T_c756b_row4_col4, #T_c756b_row6_col4, #T_c756b_row7_col4, #T_c756b_row8_col4, #T_c756b_row9_col4, #T_c756b_row10_col4, #T_c756b_row11_col4, #T_c756b_row12_col4, #T_c756b_row13_col4, #T_c756b_row14_col4, #T_c756b_row15_col4, #T_c756b_row16_col4, #T_c756b_row17_col4, #T_c756b_row18_col4, #T_c756b_row19_col4, #T_c756b_row20_col4 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c756b_row5_col2, #T_c756b_row5_col3 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c756b_row5_col4 {\n",
       "  background-color: #f5fbf3;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c756b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c756b_level0_col0\" class=\"col_heading level0 col0\" >column</th>\n",
       "      <th id=\"T_c756b_level0_col1\" class=\"col_heading level0 col1\" >type</th>\n",
       "      <th id=\"T_c756b_level0_col2\" class=\"col_heading level0 col2\" >missing</th>\n",
       "      <th id=\"T_c756b_level0_col3\" class=\"col_heading level0 col3\" >pct_missing</th>\n",
       "      <th id=\"T_c756b_level0_col4\" class=\"col_heading level0 col4\" >unique</th>\n",
       "      <th id=\"T_c756b_level0_col5\" class=\"col_heading level0 col5\" >duplicate</th>\n",
       "      <th id=\"T_c756b_level0_col6\" class=\"col_heading level0 col6\" >count</th>\n",
       "      <th id=\"T_c756b_level0_col7\" class=\"col_heading level0 col7\" >min</th>\n",
       "      <th id=\"T_c756b_level0_col8\" class=\"col_heading level0 col8\" >max</th>\n",
       "      <th id=\"T_c756b_level0_col9\" class=\"col_heading level0 col9\" >avg</th>\n",
       "      <th id=\"T_c756b_level0_col10\" class=\"col_heading level0 col10\" >std dev</th>\n",
       "      <th id=\"T_c756b_level0_col11\" class=\"col_heading level0 col11\" >top value</th>\n",
       "      <th id=\"T_c756b_level0_col12\" class=\"col_heading level0 col12\" >Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c756b_row0_col0\" class=\"data row0 col0\" >id</td>\n",
       "      <td id=\"T_c756b_row0_col1\" class=\"data row0 col1\" >int64</td>\n",
       "      <td id=\"T_c756b_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row0_col4\" class=\"data row0 col4\" >328680</td>\n",
       "      <td id=\"T_c756b_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row0_col6\" class=\"data row0 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row0_col7\" class=\"data row0 col7\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row0_col8\" class=\"data row0 col8\" >328679.000000</td>\n",
       "      <td id=\"T_c756b_row0_col9\" class=\"data row0 col9\" >164339.500000</td>\n",
       "      <td id=\"T_c756b_row0_col10\" class=\"data row0 col10\" >94881.887576</td>\n",
       "      <td id=\"T_c756b_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c756b_row1_col0\" class=\"data row1 col0\" >date</td>\n",
       "      <td id=\"T_c756b_row1_col1\" class=\"data row1 col1\" >datetime64[ns]</td>\n",
       "      <td id=\"T_c756b_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row1_col4\" class=\"data row1 col4\" >3652</td>\n",
       "      <td id=\"T_c756b_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row1_col6\" class=\"data row1 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row1_col7\" class=\"data row1 col7\" >2010-01-01 00:00:00</td>\n",
       "      <td id=\"T_c756b_row1_col8\" class=\"data row1 col8\" >2019-12-31 00:00:00</td>\n",
       "      <td id=\"T_c756b_row1_col9\" class=\"data row1 col9\" >2014-12-31 12:00:00</td>\n",
       "      <td id=\"T_c756b_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_c756b_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c756b_row2_col0\" class=\"data row2 col0\" >country</td>\n",
       "      <td id=\"T_c756b_row2_col1\" class=\"data row2 col1\" >int32</td>\n",
       "      <td id=\"T_c756b_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row2_col4\" class=\"data row2 col4\" >6</td>\n",
       "      <td id=\"T_c756b_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row2_col6\" class=\"data row2 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row2_col7\" class=\"data row2 col7\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row2_col8\" class=\"data row2 col8\" >5.000000</td>\n",
       "      <td id=\"T_c756b_row2_col9\" class=\"data row2 col9\" >2.500000</td>\n",
       "      <td id=\"T_c756b_row2_col10\" class=\"data row2 col10\" >1.707828</td>\n",
       "      <td id=\"T_c756b_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c756b_row3_col0\" class=\"data row3 col0\" >store</td>\n",
       "      <td id=\"T_c756b_row3_col1\" class=\"data row3 col1\" >int32</td>\n",
       "      <td id=\"T_c756b_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row3_col4\" class=\"data row3 col4\" >3</td>\n",
       "      <td id=\"T_c756b_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row3_col6\" class=\"data row3 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row3_col7\" class=\"data row3 col7\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row3_col8\" class=\"data row3 col8\" >2.000000</td>\n",
       "      <td id=\"T_c756b_row3_col9\" class=\"data row3 col9\" >1.000000</td>\n",
       "      <td id=\"T_c756b_row3_col10\" class=\"data row3 col10\" >0.816498</td>\n",
       "      <td id=\"T_c756b_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c756b_row4_col0\" class=\"data row4 col0\" >product</td>\n",
       "      <td id=\"T_c756b_row4_col1\" class=\"data row4 col1\" >int32</td>\n",
       "      <td id=\"T_c756b_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row4_col4\" class=\"data row4 col4\" >5</td>\n",
       "      <td id=\"T_c756b_row4_col5\" class=\"data row4 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row4_col6\" class=\"data row4 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row4_col7\" class=\"data row4 col7\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row4_col8\" class=\"data row4 col8\" >4.000000</td>\n",
       "      <td id=\"T_c756b_row4_col9\" class=\"data row4 col9\" >2.000000</td>\n",
       "      <td id=\"T_c756b_row4_col10\" class=\"data row4 col10\" >1.414216</td>\n",
       "      <td id=\"T_c756b_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c756b_row5_col0\" class=\"data row5 col0\" >y</td>\n",
       "      <td id=\"T_c756b_row5_col1\" class=\"data row5 col1\" >float64</td>\n",
       "      <td id=\"T_c756b_row5_col2\" class=\"data row5 col2\" >107421</td>\n",
       "      <td id=\"T_c756b_row5_col3\" class=\"data row5 col3\" >32.682548</td>\n",
       "      <td id=\"T_c756b_row5_col4\" class=\"data row5 col4\" >4037</td>\n",
       "      <td id=\"T_c756b_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row5_col6\" class=\"data row5 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row5_col7\" class=\"data row5 col7\" >5.000000</td>\n",
       "      <td id=\"T_c756b_row5_col8\" class=\"data row5 col8\" >5939.000000</td>\n",
       "      <td id=\"T_c756b_row5_col9\" class=\"data row5 col9\" >752.527382</td>\n",
       "      <td id=\"T_c756b_row5_col10\" class=\"data row5 col10\" >690.165445</td>\n",
       "      <td id=\"T_c756b_row5_col11\" class=\"data row5 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row5_col12\" class=\"data row5 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c756b_row6_col0\" class=\"data row6 col0\" >dataset</td>\n",
       "      <td id=\"T_c756b_row6_col1\" class=\"data row6 col1\" >object</td>\n",
       "      <td id=\"T_c756b_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row6_col3\" class=\"data row6 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row6_col4\" class=\"data row6 col4\" >2</td>\n",
       "      <td id=\"T_c756b_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row6_col6\" class=\"data row6 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row6_col7\" class=\"data row6 col7\" >nan</td>\n",
       "      <td id=\"T_c756b_row6_col8\" class=\"data row6 col8\" >nan</td>\n",
       "      <td id=\"T_c756b_row6_col9\" class=\"data row6 col9\" >nan</td>\n",
       "      <td id=\"T_c756b_row6_col10\" class=\"data row6 col10\" >nan</td>\n",
       "      <td id=\"T_c756b_row6_col11\" class=\"data row6 col11\" >train</td>\n",
       "      <td id=\"T_c756b_row6_col12\" class=\"data row6 col12\" >230130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c756b_row7_col0\" class=\"data row7 col0\" >holiday</td>\n",
       "      <td id=\"T_c756b_row7_col1\" class=\"data row7 col1\" >int32</td>\n",
       "      <td id=\"T_c756b_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row7_col3\" class=\"data row7 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row7_col4\" class=\"data row7 col4\" >75</td>\n",
       "      <td id=\"T_c756b_row7_col5\" class=\"data row7 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row7_col6\" class=\"data row7 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row7_col7\" class=\"data row7 col7\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row7_col8\" class=\"data row7 col8\" >74.000000</td>\n",
       "      <td id=\"T_c756b_row7_col9\" class=\"data row7 col9\" >4.791804</td>\n",
       "      <td id=\"T_c756b_row7_col10\" class=\"data row7 col10\" >5.508516</td>\n",
       "      <td id=\"T_c756b_row7_col11\" class=\"data row7 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row7_col12\" class=\"data row7 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c756b_row8_col0\" class=\"data row8 col0\" >Year</td>\n",
       "      <td id=\"T_c756b_row8_col1\" class=\"data row8 col1\" >int32</td>\n",
       "      <td id=\"T_c756b_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row8_col3\" class=\"data row8 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row8_col4\" class=\"data row8 col4\" >10</td>\n",
       "      <td id=\"T_c756b_row8_col5\" class=\"data row8 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row8_col6\" class=\"data row8 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row8_col7\" class=\"data row8 col7\" >2010.000000</td>\n",
       "      <td id=\"T_c756b_row8_col8\" class=\"data row8 col8\" >2019.000000</td>\n",
       "      <td id=\"T_c756b_row8_col9\" class=\"data row8 col9\" >2014.499726</td>\n",
       "      <td id=\"T_c756b_row8_col10\" class=\"data row8 col10\" >2.871904</td>\n",
       "      <td id=\"T_c756b_row8_col11\" class=\"data row8 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row8_col12\" class=\"data row8 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c756b_row9_col0\" class=\"data row9 col0\" >Quarter</td>\n",
       "      <td id=\"T_c756b_row9_col1\" class=\"data row9 col1\" >int32</td>\n",
       "      <td id=\"T_c756b_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row9_col3\" class=\"data row9 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row9_col4\" class=\"data row9 col4\" >4</td>\n",
       "      <td id=\"T_c756b_row9_col5\" class=\"data row9 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row9_col6\" class=\"data row9 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row9_col7\" class=\"data row9 col7\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row9_col8\" class=\"data row9 col8\" >3.000000</td>\n",
       "      <td id=\"T_c756b_row9_col9\" class=\"data row9 col9\" >1.508762</td>\n",
       "      <td id=\"T_c756b_row9_col10\" class=\"data row9 col10\" >1.117021</td>\n",
       "      <td id=\"T_c756b_row9_col11\" class=\"data row9 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row9_col12\" class=\"data row9 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_c756b_row10_col0\" class=\"data row10 col0\" >Month</td>\n",
       "      <td id=\"T_c756b_row10_col1\" class=\"data row10 col1\" >int32</td>\n",
       "      <td id=\"T_c756b_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row10_col3\" class=\"data row10 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row10_col4\" class=\"data row10 col4\" >12</td>\n",
       "      <td id=\"T_c756b_row10_col5\" class=\"data row10 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row10_col6\" class=\"data row10 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row10_col7\" class=\"data row10 col7\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row10_col8\" class=\"data row10 col8\" >11.000000</td>\n",
       "      <td id=\"T_c756b_row10_col9\" class=\"data row10 col9\" >5.523549</td>\n",
       "      <td id=\"T_c756b_row10_col10\" class=\"data row10 col10\" >3.448538</td>\n",
       "      <td id=\"T_c756b_row10_col11\" class=\"data row10 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row10_col12\" class=\"data row10 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_c756b_row11_col0\" class=\"data row11 col0\" >day_of_month</td>\n",
       "      <td id=\"T_c756b_row11_col1\" class=\"data row11 col1\" >int32</td>\n",
       "      <td id=\"T_c756b_row11_col2\" class=\"data row11 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row11_col3\" class=\"data row11 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row11_col4\" class=\"data row11 col4\" >31</td>\n",
       "      <td id=\"T_c756b_row11_col5\" class=\"data row11 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row11_col6\" class=\"data row11 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row11_col7\" class=\"data row11 col7\" >1.000000</td>\n",
       "      <td id=\"T_c756b_row11_col8\" class=\"data row11 col8\" >31.000000</td>\n",
       "      <td id=\"T_c756b_row11_col9\" class=\"data row11 col9\" >15.727820</td>\n",
       "      <td id=\"T_c756b_row11_col10\" class=\"data row11 col10\" >8.799338</td>\n",
       "      <td id=\"T_c756b_row11_col11\" class=\"data row11 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row11_col12\" class=\"data row11 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_c756b_row12_col0\" class=\"data row12 col0\" >day_of_week</td>\n",
       "      <td id=\"T_c756b_row12_col1\" class=\"data row12 col1\" >int32</td>\n",
       "      <td id=\"T_c756b_row12_col2\" class=\"data row12 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row12_col3\" class=\"data row12 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row12_col4\" class=\"data row12 col4\" >7</td>\n",
       "      <td id=\"T_c756b_row12_col5\" class=\"data row12 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row12_col6\" class=\"data row12 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row12_col7\" class=\"data row12 col7\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row12_col8\" class=\"data row12 col8\" >6.000000</td>\n",
       "      <td id=\"T_c756b_row12_col9\" class=\"data row12 col9\" >2.998631</td>\n",
       "      <td id=\"T_c756b_row12_col10\" class=\"data row12 col10\" >1.999660</td>\n",
       "      <td id=\"T_c756b_row12_col11\" class=\"data row12 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row12_col12\" class=\"data row12 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_c756b_row13_col0\" class=\"data row13 col0\" >week_of_year</td>\n",
       "      <td id=\"T_c756b_row13_col1\" class=\"data row13 col1\" >int32</td>\n",
       "      <td id=\"T_c756b_row13_col2\" class=\"data row13 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row13_col3\" class=\"data row13 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row13_col4\" class=\"data row13 col4\" >53</td>\n",
       "      <td id=\"T_c756b_row13_col5\" class=\"data row13 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row13_col6\" class=\"data row13 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row13_col7\" class=\"data row13 col7\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row13_col8\" class=\"data row13 col8\" >52.000000</td>\n",
       "      <td id=\"T_c756b_row13_col9\" class=\"data row13 col9\" >26.413472</td>\n",
       "      <td id=\"T_c756b_row13_col10\" class=\"data row13 col10\" >15.059286</td>\n",
       "      <td id=\"T_c756b_row13_col11\" class=\"data row13 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row13_col12\" class=\"data row13 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_c756b_row14_col0\" class=\"data row14 col0\" >day_of_month_sin</td>\n",
       "      <td id=\"T_c756b_row14_col1\" class=\"data row14 col1\" >float32</td>\n",
       "      <td id=\"T_c756b_row14_col2\" class=\"data row14 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row14_col3\" class=\"data row14 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row14_col4\" class=\"data row14 col4\" >31</td>\n",
       "      <td id=\"T_c756b_row14_col5\" class=\"data row14 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row14_col6\" class=\"data row14 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row14_col7\" class=\"data row14 col7\" >-0.998717</td>\n",
       "      <td id=\"T_c756b_row14_col8\" class=\"data row14 col8\" >0.998717</td>\n",
       "      <td id=\"T_c756b_row14_col9\" class=\"data row14 col9\" >0.001415</td>\n",
       "      <td id=\"T_c756b_row14_col10\" class=\"data row14 col10\" >0.713458</td>\n",
       "      <td id=\"T_c756b_row14_col11\" class=\"data row14 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row14_col12\" class=\"data row14 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_c756b_row15_col0\" class=\"data row15 col0\" >day_of_month_cos</td>\n",
       "      <td id=\"T_c756b_row15_col1\" class=\"data row15 col1\" >float32</td>\n",
       "      <td id=\"T_c756b_row15_col2\" class=\"data row15 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row15_col3\" class=\"data row15 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row15_col4\" class=\"data row15 col4\" >16</td>\n",
       "      <td id=\"T_c756b_row15_col5\" class=\"data row15 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row15_col6\" class=\"data row15 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row15_col7\" class=\"data row15 col7\" >-0.994869</td>\n",
       "      <td id=\"T_c756b_row15_col8\" class=\"data row15 col8\" >1.000000</td>\n",
       "      <td id=\"T_c756b_row15_col9\" class=\"data row15 col9\" >-0.018386</td>\n",
       "      <td id=\"T_c756b_row15_col10\" class=\"data row15 col10\" >0.700342</td>\n",
       "      <td id=\"T_c756b_row15_col11\" class=\"data row15 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row15_col12\" class=\"data row15 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_c756b_row16_col0\" class=\"data row16 col0\" >month_sin</td>\n",
       "      <td id=\"T_c756b_row16_col1\" class=\"data row16 col1\" >float32</td>\n",
       "      <td id=\"T_c756b_row16_col2\" class=\"data row16 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row16_col3\" class=\"data row16 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row16_col4\" class=\"data row16 col4\" >8</td>\n",
       "      <td id=\"T_c756b_row16_col5\" class=\"data row16 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row16_col6\" class=\"data row16 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row16_col7\" class=\"data row16 col7\" >-1.000000</td>\n",
       "      <td id=\"T_c756b_row16_col8\" class=\"data row16 col8\" >1.000000</td>\n",
       "      <td id=\"T_c756b_row16_col9\" class=\"data row16 col9\" >-0.004904</td>\n",
       "      <td id=\"T_c756b_row16_col10\" class=\"data row16 col10\" >0.705735</td>\n",
       "      <td id=\"T_c756b_row16_col11\" class=\"data row16 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row16_col12\" class=\"data row16 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_c756b_row17_col0\" class=\"data row17 col0\" >month_cos</td>\n",
       "      <td id=\"T_c756b_row17_col1\" class=\"data row17 col1\" >float32</td>\n",
       "      <td id=\"T_c756b_row17_col2\" class=\"data row17 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row17_col3\" class=\"data row17 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row17_col4\" class=\"data row17 col4\" >8</td>\n",
       "      <td id=\"T_c756b_row17_col5\" class=\"data row17 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row17_col6\" class=\"data row17 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row17_col7\" class=\"data row17 col7\" >-1.000000</td>\n",
       "      <td id=\"T_c756b_row17_col8\" class=\"data row17 col8\" >1.000000</td>\n",
       "      <td id=\"T_c756b_row17_col9\" class=\"data row17 col9\" >-0.002098</td>\n",
       "      <td id=\"T_c756b_row17_col10\" class=\"data row17 col10\" >0.708451</td>\n",
       "      <td id=\"T_c756b_row17_col11\" class=\"data row17 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row17_col12\" class=\"data row17 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_c756b_row18_col0\" class=\"data row18 col0\" >year_sin</td>\n",
       "      <td id=\"T_c756b_row18_col1\" class=\"data row18 col1\" >float32</td>\n",
       "      <td id=\"T_c756b_row18_col2\" class=\"data row18 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row18_col3\" class=\"data row18 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row18_col4\" class=\"data row18 col4\" >7</td>\n",
       "      <td id=\"T_c756b_row18_col5\" class=\"data row18 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row18_col6\" class=\"data row18 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row18_col7\" class=\"data row18 col7\" >-0.974928</td>\n",
       "      <td id=\"T_c756b_row18_col8\" class=\"data row18 col8\" >0.974928</td>\n",
       "      <td id=\"T_c756b_row18_col9\" class=\"data row18 col9\" >0.219063</td>\n",
       "      <td id=\"T_c756b_row18_col10\" class=\"data row18 col10\" >0.690902</td>\n",
       "      <td id=\"T_c756b_row18_col11\" class=\"data row18 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row18_col12\" class=\"data row18 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_c756b_row19_col0\" class=\"data row19 col0\" >year_cos</td>\n",
       "      <td id=\"T_c756b_row19_col1\" class=\"data row19 col1\" >float32</td>\n",
       "      <td id=\"T_c756b_row19_col2\" class=\"data row19 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row19_col3\" class=\"data row19 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row19_col4\" class=\"data row19 col4\" >4</td>\n",
       "      <td id=\"T_c756b_row19_col5\" class=\"data row19 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row19_col6\" class=\"data row19 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row19_col7\" class=\"data row19 col7\" >-0.900969</td>\n",
       "      <td id=\"T_c756b_row19_col8\" class=\"data row19 col8\" >1.000000</td>\n",
       "      <td id=\"T_c756b_row19_col9\" class=\"data row19 col9\" >-0.049945</td>\n",
       "      <td id=\"T_c756b_row19_col10\" class=\"data row19 col10\" >0.687085</td>\n",
       "      <td id=\"T_c756b_row19_col11\" class=\"data row19 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row19_col12\" class=\"data row19 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c756b_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_c756b_row20_col0\" class=\"data row20 col0\" >Group</td>\n",
       "      <td id=\"T_c756b_row20_col1\" class=\"data row20 col1\" >int32</td>\n",
       "      <td id=\"T_c756b_row20_col2\" class=\"data row20 col2\" >0</td>\n",
       "      <td id=\"T_c756b_row20_col3\" class=\"data row20 col3\" >0.000000</td>\n",
       "      <td id=\"T_c756b_row20_col4\" class=\"data row20 col4\" >481</td>\n",
       "      <td id=\"T_c756b_row20_col5\" class=\"data row20 col5\" >0</td>\n",
       "      <td id=\"T_c756b_row20_col6\" class=\"data row20 col6\" >328680</td>\n",
       "      <td id=\"T_c756b_row20_col7\" class=\"data row20 col7\" >4.000000</td>\n",
       "      <td id=\"T_c756b_row20_col8\" class=\"data row20 col8\" >484.000000</td>\n",
       "      <td id=\"T_c756b_row20_col9\" class=\"data row20 col9\" >243.912377</td>\n",
       "      <td id=\"T_c756b_row20_col10\" class=\"data row20 col10\" >138.548865</td>\n",
       "      <td id=\"T_c756b_row20_col11\" class=\"data row20 col11\" >nan</td>\n",
       "      <td id=\"T_c756b_row20_col12\" class=\"data row20 col12\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x213660c8e00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "describe_dataframe(df, name='Sales Data', nrows=0, plots=False, info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b962a-1958-4b6f-bcd9-73142d926e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a38d996-fc5c-411f-bffb-b822e0fe1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with zero \n",
    "# Drop rows where 'dataset' is 'train' and 'num_sold' is NaN\n",
    "df = df[~((df['dataset'] == 'train') & (df['y'].isna()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69156aa2-4e9b-4dd3-b8b7-c955dac099f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables (country, store, product) as dummy variables\n",
    "# Avoiding the dummy variable trap by dropping the first category in each column\n",
    "\n",
    "df = pd.get_dummies(df, columns=['country', 'store', 'product'], dtype=int, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e229d-3501-4cd5-88e6-f9cd5f6d2b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ab92afe-b0b1-4bcf-899d-09a93a10e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(24,8)})\n",
    "# ax=sns.lineplot(data=df_train,x='Day of Year',y='y')\n",
    "# ax.axes.set_title(\"\\nBasic Time Series of Sales\\n\",fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "809f5a96-8033-41f3-a2b4-c80ebca1207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(24,8)})\n",
    "# ax=sns.lineplot(data=df_train,x='Week of Year',y='y')\n",
    "# ax.axes.set_title(\"\\nBasic Time Series of Sales\\n\",fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e519bab-dc82-4f69-9f00-e3ed80784f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(24,8)})\n",
    "# ax=sns.lineplot(data=df_train,x='Month',y='y')\n",
    "# ax.axes.set_title(\"\\nBasic Time Series of Sales\\n\",fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b98f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd930c7c-10c7-4080-98c8-d7097d893708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training dataset into train and validation sets\n",
    "# Ensuring the split preserves the time series order\n",
    "\n",
    "# Separate train and test datasets\n",
    "train_df = df[df['dataset'] == 'train'].drop(columns=['dataset'], errors='ignore')\n",
    "test_df = df[df['dataset'] == 'test'].drop(columns=['dataset'], errors='ignore')\n",
    "\n",
    "\n",
    "# Drop unnecessary columns from both datasets\n",
    "train_df = train_df.drop(columns=['id'], errors='ignore')\n",
    "test_df = test_df.drop(columns=['y'], errors='ignore')\n",
    "\n",
    "# Sort training data by date to preserve time series order\n",
    "train_df = train_df.sort_values(by='date')\n",
    "\n",
    "# Let's define a split date or index\n",
    "train_size = int(len(train_df) * 0.86)  # 80% for training\n",
    "df_train = train_df.iloc[:train_size]\n",
    "df_test = train_df.iloc[train_size:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d15034a-ad00-43ab-a7a5-8fd3425567bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in\n",
    "    ## Target Encode Important Categories\n",
    "    # Step 1: Calculate the target encoding for the training data (mean price for each city)\n",
    "    df_train['holiday_encoded'] = np.nan\n",
    "    \n",
    "    # Calculate cumulative encoding for the training set (up to each time point)\n",
    "    overall_mean = df_train['y'].mean()\n",
    "    holiday_mean = df_train.groupby('holiday')['y'].expanding().mean().reset_index(level=0, drop=True)\n",
    "    \n",
    "    # Apply smoothing to the cumulative encoding\n",
    "    smoothing_factor = 10  # A smoothing factor (hyperparameter)\n",
    "    df_train['holiday_encoded'] = (holiday_mean * smoothing_factor + overall_mean) / (smoothing_factor + 1)\n",
    "    \n",
    "    # Step 2: Apply the same encoding to the test data (use training data encoding)\n",
    "    # We map the mean encoded values from the training set to the test set\n",
    "    holiday_mean_dict = df_train.groupby('holiday')['holiday_encoded'].last().to_dict()\n",
    "    \n",
    "    # Apply encoding to the test set using the mapping from training data\n",
    "    df_test['holiday_encoded'] = df_test['holiday'].map(holiday_mean_dict).fillna(overall_mean)  # Fill missing with overall mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e5b42de-d2c4-4f3e-b6dd-1bde72b46612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a logarithmic transformation to 'num_sold' to reduce skewness and stabilize variance.\n",
    "# This transformation helps to handle outliers by compressing large values, making the data \n",
    "# more suitable for statistical analysis and modeling.\n",
    "df_test['y'] = np.log(df_test['y'])\n",
    "df_train['y'] = np.log(df_train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a35cfeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "x_train = df_train.drop(['y'], axis=1)\n",
    "y_train = df_train['y']\n",
    "x_test = df_test.drop(['y'], axis=1)\n",
    "y_test = df_test['y']\n",
    "\n",
    "# Drop the 'date' column after feature extraction\n",
    "x_train = x_train.drop(columns=['date'], errors='ignore')\n",
    "x_test = x_test.drop(columns=['date'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7943187c-1a08-47f9-abf6-a2ca00d987d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:15:26,623] A new study created in memory with name: no-name-05f66994-c41f-4436-a878-c2cfeef6d406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:15:42,481] Trial 0 finished with value: 0.9022900111569755 and parameters: {'num_leaves': 56, 'learning_rate': 0.0007610300275137323, 'n_estimators': 1400, 'subsample': 0.5728608342531958, 'colsample_bytree': 0.5385785384400743}. Best is trial 0 with value: 0.9022900111569755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:15:48,377] Trial 1 finished with value: 1.4202408067058039 and parameters: {'num_leaves': 52, 'learning_rate': 0.00027296067020771933, 'n_estimators': 500, 'subsample': 0.6204542498938788, 'colsample_bytree': 0.6073588931713898}. Best is trial 0 with value: 0.9022900111569755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:16:08,069] Trial 2 finished with value: 1.2091217785191164 and parameters: {'num_leaves': 110, 'learning_rate': 0.0003704031184796096, 'n_estimators': 1100, 'subsample': 0.6855293832063633, 'colsample_bytree': 0.6193010799198598}. Best is trial 0 with value: 0.9022900111569755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:16:25,214] Trial 3 finished with value: 0.11547877533231965 and parameters: {'num_leaves': 80, 'learning_rate': 0.023071906204228377, 'n_estimators': 1300, 'subsample': 0.8654913173668192, 'colsample_bytree': 0.7385625242886689}. Best is trial 3 with value: 0.11547877533231965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:16:33,630] Trial 4 finished with value: 0.11113639888659647 and parameters: {'num_leaves': 24, 'learning_rate': 0.09928613465265598, 'n_estimators': 1500, 'subsample': 0.5096785353685278, 'colsample_bytree': 0.5906224362052088}. Best is trial 4 with value: 0.11113639888659647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:16:52,774] Trial 5 finished with value: 1.1339349200227622 and parameters: {'num_leaves': 79, 'learning_rate': 0.0003457193217291598, 'n_estimators': 1300, 'subsample': 0.9232112316987711, 'colsample_bytree': 0.6778298786240577}. Best is trial 4 with value: 0.11113639888659647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:17:04,301] Trial 6 finished with value: 0.12048822926380615 and parameters: {'num_leaves': 107, 'learning_rate': 0.009845248268836634, 'n_estimators': 600, 'subsample': 0.9965762059079977, 'colsample_bytree': 0.7744659673570922}. Best is trial 4 with value: 0.11113639888659647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:17:10,835] Trial 7 finished with value: 0.11144720622986712 and parameters: {'num_leaves': 21, 'learning_rate': 0.022018460604889396, 'n_estimators': 900, 'subsample': 0.9050002733557506, 'colsample_bytree': 0.9972954790668409}. Best is trial 4 with value: 0.11113639888659647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:17:23,444] Trial 8 finished with value: 0.11614388923242498 and parameters: {'num_leaves': 66, 'learning_rate': 0.01821669734371489, 'n_estimators': 1000, 'subsample': 0.709727684554111, 'colsample_bytree': 0.560123274391349}. Best is trial 4 with value: 0.11113639888659647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:17:32,203] Trial 9 finished with value: 1.1585342412623774 and parameters: {'num_leaves': 45, 'learning_rate': 0.00042350111091748414, 'n_estimators': 800, 'subsample': 0.9561479693353355, 'colsample_bytree': 0.8346588621951668}. Best is trial 4 with value: 0.11113639888659647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:17:40,009] Trial 10 finished with value: 0.11360639357794672 and parameters: {'num_leaves': 22, 'learning_rate': 0.09488815380336711, 'n_estimators': 1500, 'subsample': 0.5116773823761371, 'colsample_bytree': 0.9440367060605828}. Best is trial 4 with value: 0.11113639888659647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:17:44,746] Trial 11 finished with value: 0.11615220759411447 and parameters: {'num_leaves': 17, 'learning_rate': 0.09543008404892489, 'n_estimators': 900, 'subsample': 0.8145947499531339, 'colsample_bytree': 0.9648629881280442}. Best is trial 4 with value: 0.11113639888659647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:17:55,637] Trial 12 finished with value: 0.15473767382277318 and parameters: {'num_leaves': 32, 'learning_rate': 0.003548906396170598, 'n_estimators': 1100, 'subsample': 0.8320817142166884, 'colsample_bytree': 0.8727563707672561}. Best is trial 4 with value: 0.11113639888659647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:18:01,442] Trial 13 finished with value: 0.10952964165000385 and parameters: {'num_leaves': 35, 'learning_rate': 0.037699447681958924, 'n_estimators': 700, 'subsample': 0.7693837530165157, 'colsample_bytree': 0.994155603614214}. Best is trial 13 with value: 0.10952964165000385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:18:07,551] Trial 14 finished with value: 0.11244867308809377 and parameters: {'num_leaves': 38, 'learning_rate': 0.04758124857488313, 'n_estimators': 700, 'subsample': 0.7656189386587433, 'colsample_bytree': 0.71261409705729}. Best is trial 13 with value: 0.10952964165000385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:18:15,789] Trial 15 finished with value: 0.23811733484984351 and parameters: {'num_leaves': 90, 'learning_rate': 0.004344564321177016, 'n_estimators': 500, 'subsample': 0.6455242352644194, 'colsample_bytree': 0.8793961507405915}. Best is trial 13 with value: 0.10952964165000385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:18:29,951] Trial 16 finished with value: 0.14229385241214593 and parameters: {'num_leaves': 127, 'learning_rate': 0.008641885074043822, 'n_estimators': 700, 'subsample': 0.5030239059867223, 'colsample_bytree': 0.6496089961876197}. Best is trial 13 with value: 0.10952964165000385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:18:41,275] Trial 17 finished with value: 0.7462725676195038 and parameters: {'num_leaves': 35, 'learning_rate': 0.0013687846773296336, 'n_estimators': 1200, 'subsample': 0.7492752966635511, 'colsample_bytree': 0.5036475036952318}. Best is trial 13 with value: 0.10952964165000385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:18:55,561] Trial 18 finished with value: 0.11194286369611825 and parameters: {'num_leaves': 59, 'learning_rate': 0.04678111852857143, 'n_estimators': 1500, 'subsample': 0.5917627295176623, 'colsample_bytree': 0.791070387576193}. Best is trial 13 with value: 0.10952964165000385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:19:02,019] Trial 19 finished with value: 0.11060930323892267 and parameters: {'num_leaves': 30, 'learning_rate': 0.04547729864340554, 'n_estimators': 800, 'subsample': 0.7590975266169664, 'colsample_bytree': 0.9020217254696885}. Best is trial 13 with value: 0.10952964165000385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:19:09,876] Trial 20 finished with value: 0.12878772473136654 and parameters: {'num_leaves': 44, 'learning_rate': 0.006776074020800661, 'n_estimators': 700, 'subsample': 0.8084050753365349, 'colsample_bytree': 0.9186992191534045}. Best is trial 13 with value: 0.10952964165000385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:19:15,822] Trial 21 finished with value: 0.11215086359685163 and parameters: {'num_leaves': 27, 'learning_rate': 0.05624509533617812, 'n_estimators': 900, 'subsample': 0.7647250655900052, 'colsample_bytree': 0.904520491073572}. Best is trial 13 with value: 0.10952964165000385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:19:23,981] Trial 22 finished with value: 1.4284859450737872 and parameters: {'num_leaves': 30, 'learning_rate': 0.00011985932065148626, 'n_estimators': 800, 'subsample': 0.7207099464385518, 'colsample_bytree': 0.831721946471568}. Best is trial 13 with value: 0.10952964165000385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:19:30,052] Trial 23 finished with value: 0.11049854811706891 and parameters: {'num_leaves': 44, 'learning_rate': 0.03385178620454722, 'n_estimators': 600, 'subsample': 0.6699396143814071, 'colsample_bytree': 0.9924884360423597}. Best is trial 13 with value: 0.10952964165000385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 47572, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.934451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 95142, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.950947\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 142712, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.955299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 13:19:36,250] Trial 24 finished with value: 0.10893276041594904 and parameters: {'num_leaves': 46, 'learning_rate': 0.032842748318338395, 'n_estimators': 600, 'subsample': 0.6693747033711126, 'colsample_bytree': 0.9969485760047962}. Best is trial 24 with value: 0.10893276041594904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'num_leaves': 46, 'learning_rate': 0.032842748318338395, 'n_estimators': 600, 'subsample': 0.6693747033711126, 'colsample_bytree': 0.9969485760047962}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Define the objective function for Optuna, which evaluates LightGBM's performance\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameter values to be optimized by Optuna\n",
    "    params = {\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 128),  # Maximum leaves in one tree\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),  # Learning rate for gradient boosting\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 1500, step=100),  # Number of boosting rounds\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),  # Fraction of samples used per iteration\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),  # Fraction of features used for each tree\n",
    "        \"random_state\": SEED,  # Ensures reproducibility\n",
    "    }\n",
    "    \n",
    "    # Use TimeSeriesSplit to preserve temporal order during cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    model = LGBMRegressor(**params)  # Initialize the LightGBM model with current parameters\n",
    "    \n",
    "    errors = []  # List to store validation errors for each fold\n",
    "    for train_index, val_index in tscv.split(x_train):  # Split training data for cross-validation\n",
    "        x_train_cv, X_val_cv = x_train.iloc[train_index], x_train.iloc[val_index]  # Train/validation splits\n",
    "        y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        model.fit(x_train_cv, y_train_cv)  # Train the model on the current fold\n",
    "        y_val_pred = model.predict(X_val_cv)  # Predict on the validation set\n",
    "        errors.append(mean_squared_error(y_val_cv, y_val_pred))  # Calculate and store MSE\n",
    "        # Calculate MAPE and store it\n",
    "        \n",
    "    # Calculate the Root Mean Squared Error (RMSE) for the current trial\n",
    "    rmse = np.sqrt(np.mean(errors))\n",
    "    return rmse  # Return RMSE as the objective value for Optuna to minimize\n",
    "\n",
    "# Initialize an Optuna study for hyperparameter optimization\n",
    "study = optuna.create_study(direction=\"minimize\")  # Minimize RMSE\n",
    "study.optimize(objective, n_trials=25)  # Optimize the objective function over 30 trials\n",
    "\n",
    "# Print the best hyperparameters found during optimization\n",
    "print(\"Best trial:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb54ec-48cd-4b1f-b769-0075e8c108d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b98edc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b2beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74800ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'num_leaves': 46, 'learning_rate': 0.032842748318338395, 'n_estimators': 600, 'subsample': 0.6693747033711126, 'colsample_bytree': 0.9969485760047962}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 798\n",
      "[LightGBM] [Info] Number of data points in the train set: 190282, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 5.937273\n",
      "Final test RMSE: 0.07952625106614762\n",
      "Final test MAPE: 0.012040915488503006\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters found during Optuna optimization\n",
    "best_params = study.best_trial.params\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Instantiate the LightGBM model using the best hyperparameters\n",
    "final_model = LGBMRegressor(**best_params)\n",
    "\n",
    "# Train the model on the training dataset\n",
    "final_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict the target variable for the test dataset\n",
    "y_test_pred = final_model.predict(x_test)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for model evaluation\n",
    "# RMSE indicates the average magnitude of prediction errors, lower is better\n",
    "final_test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Final test RMSE:\", final_test_rmse)\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE) for model evaluation\n",
    "# MAPE shows the average percentage error between predicted and actual values, lower is better\n",
    "final_test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "print(\"Final test MAPE:\", final_test_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1730e9ea-76f2-41e2-8127-8e383e59a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test RMSE: 0.0760734597586072/\n",
    "# Final test MAPE: 0.011637640001178647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2253c8a2-3856-4d21-a14f-df331c8504af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'num_leaves': 46, 'learning_rate': 0.032842748318338395, 'n_estimators': 600, 'subsample': 0.6693747033711126, 'colsample_bytree': 0.9969485760047962}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 221259, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 752.527382\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.9969485760047962,\n",
       "              learning_rate=0.032842748318338395, n_estimators=600,\n",
       "              num_leaves=46, subsample=0.6693747033711126)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(colsample_bytree=0.9969485760047962,\n",
       "              learning_rate=0.032842748318338395, n_estimators=600,\n",
       "              num_leaves=46, subsample=0.6693747033711126)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.9969485760047962,\n",
       "              learning_rate=0.032842748318338395, n_estimators=600,\n",
       "              num_leaves=46, subsample=0.6693747033711126)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features (X) and target variable (y) from the training data\n",
    "# Dropping 'num_sold' as it's the target variable\n",
    "# Dropping 'date' to avoid any unintended leakage since it is not used as a feature\n",
    "X = train_df.drop(columns=['y', 'date']).copy()\n",
    "y = train_df['y'].copy()\n",
    "\n",
    "# Retrieve the best hyperparameters from the Optuna study\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Instantiate the LightGBM model with the optimal hyperparameters\n",
    "best_model = LGBMRegressor(**best_params)\n",
    "\n",
    "# Train the model using all available training data (X, y)\n",
    "best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc5ac23f-a5df-4975-b891-fa4e9e1160fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature importance values\n",
    "# importance = model.feature_importances_\n",
    "importance = best_model.feature_importances_\n",
    "\n",
    "# Feature names\n",
    "feature_names = X.columns if isinstance(X, pd.DataFrame) else [f'Feature {i}' for i in range(X.shape[1])]\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"LightGBM Feature Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c6d94ded-695e-4201-9588-14be6a3ef7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess test data\n",
    "test_features = test_df.drop(columns=['id', 'date'], errors='ignore')  # Drop unnecessary columns\n",
    "# Apply encoding to the test set using the mapping from training data\n",
    "test_features = test_features.reindex(columns=x_train.columns, fill_value=0)  # Align columns with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3a203565",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8e77c9fb-49f6-40b9-ab84-6bf1d9f0f6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zchodan\\AppData\\Local\\Temp\\1\\ipykernel_7272\\21123771.py:2: RuntimeWarning: overflow encountered in expm1\n",
      "  sub[target_variable] = np.expm1(y_test_pred)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98550, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230130</td>\n",
       "      <td>6.625833e+73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230131</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230132</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230133</td>\n",
       "      <td>8.645788e+185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230134</td>\n",
       "      <td>2.842462e+226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id       num_sold\n",
       "0  230130   6.625833e+73\n",
       "1  230131            inf\n",
       "2  230132            inf\n",
       "3  230133  8.645788e+185\n",
       "4  230134  2.842462e+226"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(submission_path)\n",
    "sub[target_variable] = np.expm1(y_test_pred)\n",
    "sub.to_csv('Predictions_LGBM.csv', index=False)\n",
    "print(sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc755366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
